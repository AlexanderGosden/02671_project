{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from math import floor, ceil\n",
    "\n",
    "\n",
    "def boximage(box_width, box_height, width = 200, height = 200, center = None):\n",
    "    if center is None:\n",
    "        center = ((height-1)/2, (width-1)/2)\n",
    "\n",
    "\n",
    "    im = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "\n",
    "    y_start = max(center[0]-box_height/2, 0)\n",
    "    y_end = min(center[0]+box_height/2, height-1)\n",
    "\n",
    "    x_start = max(center[1]-box_width/2, 0)\n",
    "    x_end = min(center[1]+box_width/2, width-1)\n",
    "\n",
    "    # Draw the edges\n",
    "    im[floor(y_start), ceil(x_start):floor(x_end+1)] = 255*(ceil(y_start)-y_start)\n",
    "    im[ceil(y_end), ceil(x_start):floor(x_end+1)] = 255*(y_end - floor(y_end))\n",
    "    im[ceil(y_start):floor(y_end+1), floor(x_start)] = 255*(ceil(x_start) - x_start)\n",
    "    im[ceil(y_start):floor(y_end+1), ceil(x_end)] = 255*(x_end - floor(x_end))\n",
    "\n",
    "    # Draw the four corners\n",
    "    im[floor(y_start), floor(x_start)] = 255*(ceil(y_start) - y_start)*(ceil(x_start) - x_start)\n",
    "    im[floor(y_start), ceil(x_end)] = 255*(ceil(y_start) - y_start)*(x_end - floor(x_end))\n",
    "    im[ceil(y_end), floor(x_start)] = 255*(y_end - floor(y_end))*(ceil(x_start) - x_start)\n",
    "    im[ceil(y_end), ceil(x_end)] = 255*(y_end - floor(y_end))*(x_end - floor(x_end))\n",
    "\n",
    "    # Fill the box\n",
    "    im[ceil(y_start):floor(y_end+1), ceil(x_start):floor(x_end+1)] = 255\n",
    "\n",
    "\n",
    "    return im\n",
    "\n",
    "n_frames = 100\n",
    "box_widths = np.linspace(0, 100, n_frames)\n",
    "box_heights = np.linspace(10, 90, n_frames)\n",
    "center_x = np.linspace(0, 200, n_frames)\n",
    "center_y = np.linspace(0, 200, n_frames)\n",
    "video = np.array([boximage(box_width, box_height, center = (cx, cy)) for box_width, box_height, cx, cy in zip(box_widths, box_heights, center_x, center_y)])\n",
    "\n",
    "np.save('boxvideo.npy', video)\n",
    "\n",
    "#animate video with matplotlib.funcanimation\n",
    "def animate_video(video):\n",
    "    %matplotlib tk\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 10))\n",
    "\n",
    "    def animate(frame):\n",
    "        ax.clear()\n",
    "        ax.imshow(video[frame], cmap='gray')\n",
    "        ax.set_title(f'Frame {frame}')\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=range(len(video)), interval=5, repeat=False)\n",
    "\n",
    "    return ani\n",
    "\n",
    "ani = animate_video(video)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import saved AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.AE import Encoder, Decoder, AE\n",
    "from src.utils.misc import load_config, animate_video\n",
    "import torch\n",
    "\n",
    "def build_model(model_type: str, CFG, device: str):\n",
    "    H = CFG['data']['H']\n",
    "    W = CFG['data']['W']\n",
    "    latent_dim = CFG['AE']['D']\n",
    "    if model_type == 'AutoEncoder':\n",
    "        encoder = Encoder(H, W, latent_dim)\n",
    "        decoder = Decoder(H, W, latent_dim)\n",
    "        model = AE(encoder, decoder)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "CFG = load_config('configs/config.yaml')\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = build_model('AutoEncoder', CFG, device)\n",
    "model.load_state_dict(torch.load('data/model_weights/AutoEncoder_weights.pt', map_location=device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform frame interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_linear(observed_times, new_times, states):\n",
    "    new_states = np.zeros((len(new_times), *states.shape[1:]))\n",
    "\n",
    "    for j, time in enumerate(new_times):\n",
    "        # find the two closest observed times\n",
    "        idx = np.searchsorted(observed_times, time)\n",
    "        if idx == 0:\n",
    "            new_states[j] = states[0]\n",
    "        elif idx == len(observed_times):\n",
    "            new_states[j] = states[-1]\n",
    "        else:\n",
    "            # linearly interpolate between the two closest observed times\n",
    "            alpha = (time - observed_times[idx-1]) / (observed_times[idx] - observed_times[idx-1])\n",
    "            new_states[j] = alpha * states[idx] + (1 - alpha) * states[idx-1]\n",
    "\n",
    "    return new_states\n",
    "\n",
    "\n",
    "interpolated_video = interpolate_linear(np.arange(len(video)), np.arange(0, len(video), 0.1), video)\n",
    "\n",
    "ani = animate_video(interpolated_video)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.training.trainer import Trainer\n",
    "\n",
    "training_data = list(video.astype(np.float32))\n",
    "train_loader = DataLoader(dataset=training_data, batch_size=CFG['training']['batch_size'], shuffle=True)\n",
    "\n",
    "model = build_model('AutoEncoder', CFG, device)\n",
    "\n",
    "trainer = Trainer(model, train_loader, config_path = 'configs/config.yaml', device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [00:20<00:00,  9.66iter/s, Current loss=590]   \n"
     ]
    }
   ],
   "source": [
    "losses = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x15f097650>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = video.astype(np.float32)\n",
    "data = list(DataLoader(dataset=data, batch_size=len(data), shuffle=False))[0]\n",
    "output = model(data.to(device)).detach().cpu().numpy()\n",
    "\n",
    "%matplotlib tk\n",
    "animate_video(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform frame interpolation in encoded space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x2cfe37f50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = model.encoder(data.to(device)).detach().cpu().numpy()\n",
    "encoded_interpolated = interpolate_linear(np.arange(len(encoded)), np.arange(0, len(encoded), 0.1), encoded).astype(np.float32)\n",
    "output_interpolated = model.decoder(torch.tensor(encoded_interpolated).to(device)).detach().cpu().numpy()\n",
    "\n",
    "animate_video(output_interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciComp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
